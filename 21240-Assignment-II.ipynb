{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Questions-I from MDSC-301(P)\n",
    "\n",
    "----------------------------------------------------------------\n",
    "Author: Saikrishna B \n",
    "\n",
    "Date: August 20, 2022\n",
    "\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Which Linear Regression training algorithm can you use if you have\n",
    "a training set with millions of features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Gradient Descent is generally good, especially stochastic GD and Mini-batch GD, since they do not load the entire training dataset into memory.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Suppose the features in your training set have very different scales.\n",
    "Which algorithms might suffer from this, and how? What can you\n",
    "do about it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Gradient Descent Algorithms would suffer mainly from this, since it would be difficult for them to converge. Feature Scaling, either the normalizing method, or the Standardizing methods can be used. Generally, any method that uses distance measures to measure loss, or to classify or cluster, suffer from features that aren't in scale.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.  Suppose you use Batch Gradient Descent and you plot the validation\n",
    "error at every epoch. If you notice that the validation error\n",
    "consistently goes up, what is likely going on? How can you fix this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *There are 2 possibilities for this problem. If the training error is also going up rapidly, then the issue is with the learning rate, and it should be reduced. If the training error isnt going up, then the algorithm is overfitting to the training data and common measures to prevent overfitting should be used, like regularization, adding more data, etc.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Is it a good idea to stop Mini-batch Gradient Descent immediately\n",
    "when the validation error goes up?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *No, it is not, since the mini batches are randomly sampled. The  following batches may bring a different trend, so till a defined margin, the error should be observed before deciding a course of action.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Suppose you are using Polynomial Regression. You plot the learning\n",
    "curves and you notice that there is a large gap between the training\n",
    "error and the validation error. What is happening? What are three\n",
    "ways to solve this?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *This is the classic indicator of overfitting. Standard measures can be used as follows:*\n",
    ">\n",
    "> 1. Add more training data\n",
    "> 2. Reduce complexity of model\n",
    "> 3. L1, L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Suppose you are using Ridge Regression and you notice that the\n",
    "training error and the validation error are almost equal and fairly\n",
    "high. Would you say that the model suffers from high bias or high\n",
    "variance? Should you increase the regularization hyperparameter $\\alpha$\n",
    "or reduce it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *It suffers from High bias. Regularization hyperparameter should be reduced.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Why would you want to use:\n",
    "   - Ridge Regression instead of plain Linear Regression (i.e., without any regularization)?\n",
    "   - Lasso instead of Ridge Regression?\n",
    "   - Elastic Net instead of Lasso?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8.  Can you name four of the main challenges in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - *Ridge Regression can be used when the model is overfitting to the data.*\n",
    "> - *Lasso Regression can be used when some features have to be auto selected, because in Lasso, the weights of the important features will be dropped to near zero.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. If your model performs great on the training data but generalizes\n",
    "poorly to new instances, what is happening? Can you name three\n",
    "possible solutions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *If it performs well on training data, but doesn't generalize well, this issue is known as overfitting. Possible Solutions include:*\n",
    ">\n",
    "> 1. Adding more training data\n",
    "> 2. Changing the training algorithm\n",
    "> 3. Adding regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. What is a test set, and why would you want to use it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *A test set is a set of samples from the data, that is strictly kept unexposed to the model. It is used to test the algorithm to see if it is able to generalise well to unseen data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11.  What is the purpose of a validation set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *The validation set can be seen as a kind of testing phase during the training phase itself. One of the main uses of the validation set is to stop the model from overfitting to the training data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12. What are different loss functions? Exaplain their importance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Different Loss Functions include:*\n",
    ">\n",
    "> 1. MSE: __Mean Square Error__ is the average of the sum of the squares of the residuals  \n",
    "     <br>  \n",
    "     <p style=\"text-align: center\">$\\mathit{MSE} = \\Large\\frac{\\sum_{i=1}^{N}(y_{i} - y\\hat{}_{i})^2}{N}$</p>\n",
    "     <br>\n",
    ">    Its advantages are mainly that negative values are made positive, and huge errors are made huger. This error is also used to check the variance of the data.\n",
    ">\n",
    "> 2. MAE: __Mean Absolute Error__ is the average of the absolute values of difference of the residuals.  \n",
    "     <br>  \n",
    "     <p style=\"text-align: center\">$\\mathit{MAE} = \\sqrt{\\Large\\frac{\\sum_{i=1}^{N}\\left|(y_{i} - y\\hat{}_{i})\\right|}{N}}$</p>\n",
    "     <br>\n",
    ">    This is more robust in capturing the outliers properly, as their huge error wouldn't be maximised, as in the case of MSE.\n",
    ">\n",
    "> 3. RMSE: __Root Mean Square Error__ is the root of the average of the sum of the squares of the residuals.  \n",
    "     <br>  \n",
    "     <p style=\"text-align: center\">$\\mathit{RMSE} = \\Large\\frac{\\sum_{i=1}^{N}(y_{i} - y\\hat{}_{i})^2}{N}$</p>\n",
    "     <br>\n",
    ">    The advantage of RMSE over MSE is that, correlation can be easily found, as degree is brought from 2 to 1. The units of the predicted value and the actual value are both the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q13. Explain the following:\n",
    "    - Gradient descent\n",
    "    - Mini-batch gradient descent\n",
    "    - Batch gradient, and\n",
    "    - Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q14. What is learning rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *The learning rate is a hyperparameter that controls the impact that the gradient has on the updataion of weights.*\n",
    "    <br>\n",
    "    <p style=\"text-align: center;\">$\\large w_{i+1} = w_{i} - \\alpha (\\large\\frac{\\partial J(w, b)}{\\partial w})$</p>\n",
    "    <br> \n",
    "> *Here,* $\\Large\\alpha$ *refers to the learning rate hyperparameter.*    \n",
    "> *In this example of the gradient descent's updation step of the weights,* $\\Large\\alpha$ *scales down the effect the gradient of w has towards its updation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q15. Define the following terms. Explain their importance in the data analysis.\n",
    "    - $R^2$\n",
    "    - Adjusted $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $\\large R^2$ *and adjusted* $\\large R^2$ *are two important measures in the evaluation of the model. The latter is an improvement of the former.*\n",
    ">\n",
    "> $\\large R^2$ *is in words, the measure of the amount of variance of the dependent feature explained by the independent feature. It is given by the following formula:*  \n",
    "    <br>\n",
    "    <p style=\"text-align: center;\">$\\large R^2 = \\Large\\frac{(TSS - RSS)}{TSS}$</p>\n",
    "    <br>  \n",
    ">  \n",
    ">  \n",
    "> *Adjusted* $\\large R^2$ *is improving the normal* $\\large R^2$ *value by introducing a penalty for each feature added, so that increasing the amount of random features doesn't deceivingly improve the amount of variance explained by those unrelated random features.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q16. Explain One-Hot Encoding and Label Encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. *One Hot encoding is the technique where, categorical features are given numerical values by which the model can compute and predict. In one hot encoding, each category of a categorical feature is given a seperate feature where the value is 1 if that sample is of that category, while the value is 0 if it is not.*\n",
    ">\n",
    "> 2. *Label encoding is used for the same purpose of one hot encoding, but it is generally used when the feature has some kind of intrinsic order, asc or desc, at which point, each of the categories are given suitable values in order of their nature.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q17. What are the assumption on Naive Bayes algorithm in classification?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *There are 2 main assumptions:*\n",
    ">\n",
    "> 1. *All the features are linearly independent.*\n",
    ">\n",
    "> 2. *All the features have the same importance, (ie) they impact the outcome identically.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q18. What is the difference between classification and regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Fundementally, both are used for predictions, but the type of value they are prediciting is different. In regression, the target variable is continuous in nature, thus the predictions are basically values. However, in classification, the range of predicitions, are a set of classes that the target variable can assume, out of which one class is predicted.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q19. How to ensure that the model is not overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *There are some time tested methods to ensure the model does not overfit to the training data, as follows:*\n",
    ">\n",
    "> 1. *Usage of cross validation to test validation set error trend.*\n",
    "> 2. *Whenever possible, adding more and more training data.*\n",
    "> 3. *Selecting features responsibly, so that the model isn't unnecessarily complex.*\n",
    "> 4. *Regularization(L1, L2, etc)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q20. List the main advantage of Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Advantages of Naive Bayes are: Speed, Versitality, Small data footprint, Easy implementation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q21. What you shoud do when your model is suffereing from:\n",
    "    - Low bias and high variance?\n",
    "    - High bias and low variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - *In the case of low bias and high variance, it likely means that overfitting is happening, thus regularization should be added. Adding more training data to the model's intake defintely helps it to better generalize to unseen data.*\n",
    ">\n",
    "> - *In the case of high bias and low vairance, it is likely the case that the model is underfitting to the training data. Thus the complexitity of the model could be increased, through methods like feature ingineering. The regularization hyperparameter, could also be reduced.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q22. What is the 'Naive' in the Naive Bayes Classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *The 'Naive' in the name is likely stemming from the fact that one of the assumptions of the technique is that, all features contribute to the model identically. This seems a little \"Naive\", so to say.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q23. What is bias-variance tradeoff in Machine Learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *The bias variance tradeoff in ML, is a classic example of having to choose between the more important of two parameters to improve, sacrificing the optimization of the other.*\n",
    ">  \n",
    "> - *Here, if the bias is high, then the model may be able to generalize well to unseen data, but it may have extremely simple classification, thus may not be really useful practically.*\n",
    ">  \n",
    "> - *On the other hand, if the variance is high, the model may classify the data points, extremely well, but there is also a high risk that it may overfit to the training data, and thus not generalize well to unexposed data.*\n",
    ">  \n",
    "> *Deciding the ideal point in the tradeoff depends on minimizing the noise, and both the bias and vairance errors.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q24. Explain different trade-offs in Machine Learning algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - *Bias- Variance tradeoff*\n",
    ">\n",
    "> - *Precision - recall tradeoff*\n",
    ">\n",
    "> - *Interpretibility - Accuracy tradeoff*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q25. What is cross-validation and how it is useful in traing ML models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Cross validation is a technique used mainly to prevent overfitting. The validation set is partitioned into folds, randomly sampled. The validation is done on those folds and the loss is averaged. Cross validation helps since the validation set is randomly sampled multiple times. The number of folds, is yet another hyperparameter.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
